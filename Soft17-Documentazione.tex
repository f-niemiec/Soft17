\documentclass[a4paper,11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{tabularx} % Per tabelle a larghezza fissa
\usepackage{booktabs} % Per linee professionali (toprule, midrule, bottomrule)
\usepackage[table,dvipsnames]{xcolor} % Per colorare le righe
\usepackage[export]{adjustbox}

\title{Soft17 -- An Intelligent Agent for Blackjack}
\author{Abbatiello Simone, Nappi Vincenzo, Niemiec Francesco}
\date{January 2026}

\begin{document}

\maketitle

\section{Introduzione}

\subsection{Genesi del progetto}

Durante la seconda parte del corso di \textit{Fondamenti di Intelligenza Artificiale}, in particolare quella dedicata agli argomenti di \textbf{Machine Learning}, è emerso in modo sempre più evidente il forte legame tra le tecniche di apprendimento automatico e il mondo della statistica.  

Abbiamo deciso di cogliere l’occasione offerta dallo sviluppo del progetto finale per approfondire tale correlazione, analizzandola in un contesto applicativo concreto. In seguito a una fase di brainstorming, volta a individuare un dominio che consentisse di unire questi due ambiti, abbiamo preso in considerazione i documenti forniti dal docente, nei quali il tema dei \textit{giochi} emerge come un caso di studio ricorrente.  

Guidati dalla curiosità e dalla relativa semplicità delle regole, abbiamo quindi scelto il gioco del \textbf{Blackjack}. Da questa scelta nasce l’idea di sviluppare un modello che sia in grado di stimare l’esito atteso di una mano di Blackjack sulla base delle informazioni disponibili e delle strategie tipiche.



\section{Nozioni basilari di Blackjack}
\subsection{Overview}
Il Blackjack è un gioco di carte dalla forte semplicità, non a caso è tra i più diffusi nei casinò di tutto il mondo.
Nella sua versione comune il prevede l'uso di un numero di mazzi standard di 52 carte francesi che va da 1 a 8, e coinvolge solo due tipologie di figure: il "banco" (anche detto "dealer") ed i giocatori. L’obiettivo del singolo giocatore è ottenere una mano il cui valore totale sia pari o quanto più possibile vicino a 21, senza superare tale soglia, e che risulti superiore a quello del banco. Il banco gioca secondo le stesse regole e di conseguenza perde nel momento in cui totalizza un valore minore del giocatore o quando esso sfora la soglia del ventuno. Le carte numeriche mantengono il loro normale valore, le figure valgono ciascuna 10 punti, mentre l’asso può assumere valore 1 o 11 a seconda della scelta del giocatore. 
Il gioco prende il nome dalla combinazione delle carte asso e jack nero, ma nella sua terminologia viene chiamata blackjack qualunque combinazione di un asso con una figura. Ogni partecipante compete esclusivamente contro il banco, non contro gli altri giocatori al tavolo, e può compiere una serie di scelte (come chiedere carta, stare, raddoppiare o dividere) che incidono direttamente sull’esito della mano. Ciò nonostante nella sua variante a più giocatori nel momento in cui il dealer sfora, tutti i giocatori che non sforano vincono, avendo ognuno di fatto un'influenza, anche se implicita su ciascuna partita.
La situazione iniziale di ogni partita è costituita dal dealer con due carte: una scoperta ed una coperta, ed il giocatore sulla base delle due carte che riceve deve stabilire se pescare ancora (\textbf{HIT}) o rimanere con solo quelle due carte (\textbf{STAND}).
Vi sono anche ulteriori possibilità, lo \textbf{SPLIT} può verificarsi quando vengono pescate come prime due carte dal giocatore due carte dallo stesso valore, in tal caso è possibile considerarle come due "prime carte" e giocare due mani contemporaneamente.
L'ultimo caso è il \textbf{DOUBLE} nel quale si va a raddoppiare la puntata iniziale.

Un elemento distintivo del blackjack rispetto ad altri giochi da casinò è la possibilità di intervento razionale del giocatore sull’andamento della partita. Sebbene il gioco resti fondamentalmente basato sul caso, esistono strategie matematicamente fondate, in grado di aiutare il giocatore.
Proprio quest'ultimo aspetto matematico ha portato moltissima attenzione dalla comunità scientifica sul gioco,
aprendo le porte prima ad analisi statistiche e poi a nuovi orizzonti come algoritmi genetici e modelli di Machine Learning.
\subsection{Vantaggio del banco}
Chiamiamo vantaggio del banco la misura quantitativa dello svantaggio strutturale a cui è sottoposto il giocatore di blackjack nel lungo periodo. Esso esprime la perdita media attesa per unità di puntata ed è un indicatore fondamentale per l’analisi matematica ed economica del gioco, in quanto sintetizza l’effetto congiunto delle regole, delle probabilità e dell’ordine delle decisioni.

A differenza di altri giochi da casinò, il vantaggio del banco nel blackjack non è fisso, ma dipende in modo significativo dalla configurazione regolamentare del tavolo e dal comportamento del giocatore.
L’origine del vantaggio del banco è riconducibile a una serie di asimmetrie strutturali.
La più rilevante è l’ordine di gioco: il giocatore è obbligato ad agire per primo e perde immediatamente la puntata nel caso in cui superi 21, indipendentemente dal risultato finale del banco. Questa regola, apparentemente neutrale, introduce un vantaggio matematico stabile a favore del casinò. A ciò si aggiungono le regole fisse del banco, che ne limitano la discrezionalità ma risultano, nel complesso, statisticamente ottimali.

Ulteriori contributi al vantaggio del banco derivano dalla struttura dei pagamenti. Il pagamento del blackjack naturale è un elemento cruciale: una remunerazione pari a 3:2 riduce significativamente il margine del casinò, mentre formule meno favorevoli al giocatore, come il pagamento 6:5, possono incrementare il vantaggio del banco. 
Anche il numero di mazzi utilizzati e le restrizioni sulle opzioni di gioco (raddoppio, divisione, resa) incidono in modo misurabile sul margine complessivo.

Dal punto di vista teorico, il vantaggio del banco nel blackjack è di particolare interesse perché non è imposto esclusivamente dal caso, ma emerge dall’interazione tra regole istituzionali e decisioni individuali. Esso rappresenta quindi un esempio di come un sistema apparentemente equo possa generare, attraverso vincoli asimmetrici, un esito statisticamente sfavorevole a una delle parti.

Attraverso l'attuazione di alcuni comportamenti è possibile ridurre questo svantaggio, primo di tutti è l'applicazione della strategia di base.

\subsection{Strategia di base}
Parliamo di strategia di base come dell’insieme di decisioni ottimali che il giocatore dovrebbe adottare in ogni possibile configurazione della propria mano e della carta scoperta del banco, assumendo condizioni di gioco standard e l’assenza di informazioni supplementari sull’ordine delle carte. Essa costituisce il riferimento teorico fondamentale per l’analisi razionale del gioco e per la valutazione del vantaggio statistico del banco.
Per ciascuna combinazione di mano del giocatore e carta visibile del banco, viene determinata l’azione che massimizza il valore atteso della giocata.
È importante effettuare una distinzione tra \textbf{hard-hand}, in cui l’asso ha valore fisso pari a 1, e \textbf{soft-hand}, in cui l’asso può assumere valore 11 senza rischio immediato di sballo.
L’adozione coerente della strategia di base consente di ridurre il margine di vantaggio del banco a valori minimi, che in condizioni regolamentari favorevoli possono scendere a meno del'uno percento. 
È tuttavia importante sottolineare che la strategia di base non elimina il rischio né garantisce vincite nel breve periodo: essa opera esclusivamente sul piano statistico, ottimizzando le decisioni nel lungo termine.
Nel dettaglio questa strategia è stata formalizzata nel 1956 da Roger R. Baldwin, nell'articolo "The Optimal Strategy in Blackjack". Di seguito riportiamo le tabelle relative alla strategia di base del Blackjack.

---PLACEHOLDER---

\section{Descrizione dell’agente}

\subsection{Obiettivi di business}

L’obiettivo del progetto è lo sviluppo di un \textbf{agente intelligente} in grado di:

\begin{itemize}
    \item selezionare, per ogni mano osservabile, l’azione più appropriata al fine di massimizzare il \textit{win rate}. Le azioni considerate sono:
    \begin{itemize}
        \item \textbf{Hit}: richiedere una carta aggiuntiva;
        \item \textbf{Stand}: mantenere la mano attuale;
        \item \textbf{Double}: raddoppiare la puntata iniziale e ricevere una sola carta; //Da togliere 
        \item \textbf{Split}: dividere la mano in due mani distinte in presenza di due carte uguali.
    \end{itemize}
    \item prendere decisioni esclusivamente sulla base della propria mano e della carta scoperta del dealer, senza conoscere le carte rimanenti nel mazzo;
    \item migliorare le proprie prestazioni nel tempo, apprendendo dai dati osservati.
\end{itemize}

\subsection{Specifica dell’ambiente (PEAS)}

L’ambiente in cui opera l’agente viene descritto attraverso la specifica \textbf{PEAS} (Performance, Environment, Actuators, Sensors).

\begin{description}
    \item[Performance:] la misura di prestazione dell’agente è legata alla sua capacità di massimizzare il risultato economico nel gioco. In particolare vengono considerate il numero di vittorie rispetto alle mani giocate, il guadagno netto complessivo e la capacità di adottare azioni ottimali in situazioni rischiose.
    
    \item[Environment:] l’ambiente è rappresentato da un tavolo di Blackjack comprendente:
    \begin{itemize}
        \item uno o più mazzi di carte con distribuzione stocastica;
        \item un dealer che segue una policy fissa;
        \item la mano del giocatore;
        \item l’insieme delle regole del gioco.
    \end{itemize}
    Le proprietà dell’ambiente sono:
    \begin{itemize}
        \item \textbf{Parzialmente osservabile}: l’agente conosce solo la propria mano e la carta scoperta del dealer;
        \item \textbf{Stocastico}: l’ordine delle carte nel mazzo è pseudocasuale;
        \item \textbf{Sequenziale}: ogni azione influenza l’esito finale della mano;
        \item \textbf{Statico}: l’ambiente non cambia mentre l’agente sta deliberando;
        \item \textbf{Discreto}: il numero di stati e azioni è finito;
        \item \textbf{A singolo agente}: il dealer segue una strategia prefissata e non è considerato un agente decisionale.
    \end{itemize}

    \item[Actuators:] gli attuatori dell’agente corrispondono alle azioni disponibili: Hit, Stand, Double e Split.

    \item[Sensors:] l’agente percepisce:
    \begin{itemize}
        \item le carte della propria mano;
        \item la carta scoperta del dealer;
        \item le azioni consentite in un determinato stato (ad esempio la possibilità di effettuare double o split);
        \item l’esito finale della mano (vittoria, sconfitta o pareggio).
    \end{itemize}
\end{description}

\subsection{Scelta della strategia}

Un primo approccio al problema avrebbe potuto basarsi sulla teoria dei giochi e sull’utilizzo di algoritmi genetici. Tuttavia, tale soluzione presenta diverse criticità:

\begin{description}
    \item[Variabilità dei cromosomi:] la rappresentazione delle soluzioni risulterebbe altamente variabile, rendendo complessa la codifica delle strategie.
    \item[Complessità dello spazio di ricerca:] l’elevato numero di stati e azioni comporta uno spazio di ricerca estremamente ampio, con conseguenti tempi di elaborazione proibitivi.
    \item[Inaccuratezza della fitness:] la natura stocastica dell’ambiente rende la funzione di fitness fortemente influenzata dalla casualità.
\end{description}

Alla luce di queste considerazioni, abbiamo deciso di affrontare il problema tramite tecniche di \textbf{apprendimento supervisionato}. In questo contesto, l’agente apprende una funzione che associa a ogni stato osservabile del gioco un’etichetta nota, rappresentata dall’esito della mano, utilizzando un dataset di mani simulate.

\section{Metodologia e Raccolta dati}

\subsection{Metodologia di sviluppo: CRISP-DM}

Lo sviluppo del progetto è stato guidato dal modello CRISP-DM (Cross-Industry Standard Process for Data Mining), un processo standard ampiamente adottato per la realizzazione di sistemi di data mining e machine learning. Tale modello fornisce una visione strutturata e iterativa del ciclo di vita di un progetto di apprendimento automatico, suddividendolo in fasi ben definite.

In particolare, il CRISP-DM prevede le seguenti fasi principali:
\begin{itemize}
    \item \textbf{Business Understanding}: definizione degli obiettivi del sistema e dei criteri di successo;
    \item \textbf{Data Understanding}: raccolta dei dati, analisi esplorativa e valutazione della loro qualità;
    \item \textbf{Data Preparation}: pulizia dei dati e costruzione delle feature rilevanti;
    \item \textbf{Modeling}: selezione e addestramento dei modelli di apprendimento automatico;
    \item \textbf{Evaluation}: valutazione delle prestazioni del modello rispetto agli obiettivi prefissati;
    \item \textbf{Deployment}: integrazione del modello all’interno di un sistema utilizzabile.
\end{itemize}

Nel contesto del presente lavoro, le fasi di \emph{Business Understanding} e \emph{Data Understanding} sono state affrontate attraverso la definizione degli obiettivi dell’agente intelligente e l’analisi preliminare dei dati generati dal simulatore di Blackjack. Le successive operazioni di data cleaning e feature engineering rientrano nella fase di \emph{Data Preparation}, il cui obiettivo è rendere i dati idonei all’addestramento di modelli di apprendimento supervisionato.

In conclusione, il modello CRISP-DM è stato utilizzato come \textbf{riferimento metodologico} per strutturare il progetto, senza l’obiettivo di coprirne esplicitamente tutte le fasi, ma adottandone i principi per guidare le scelte progettuali effettuate.

\subsection{Scelta del dataset}

Per la scelta del dataset sono state considerate due possibili strategie:
\begin{enumerate}
    \item Generare un dataset sintetico tramite un simulatore di Blackjack, in grado di produrre un numero arbitrario di mani realistiche.
    
    \item Utilizzare dataset già disponibili online (\url{https://www.kaggle.com/datasets/mojocolors/900000-hands-of-blackjack-results}) e (\url{https://www.kaggle.com/datasets/dennisho/blackjack-hands/data}).
\end{enumerate}

La prima opzione come pro avrebbe garantito un grande controllo sui dati, ma un errore minimo nel simulatore avrebbe o una nostra scelta sbagliata e/o inesperta nella categorizzazione dei dati avrebbe avuto un impatto troppo impatto sul modello.
La seconda opzione seppur all'apparenza più facile, avrebbe potuto celare delle insidie, come una difficile comprensione dei dataset oppure "fastidi" dovuti alla loro enorme dimensione. 
Avendo valutato per bene ambo le alternativi ci siamo trovati inizialmente di fronte ad un bivio, successivamente abbiamo optato per una soluzione "ibrida".
Il più corposo tra i principali due dataset trovati contava cinquanta milioni di mani di blackjack simulate, un numero talmente elevato che il training del modello con le risorse a nostra disposizione sarebbe risultato infito. Esso però riportava anche una repository \textbf{GitHub} con il programma usato per simulare queste mani.
Abbiamo quindi preso questo programma e generato un dataset con circa cinquecentomila mani giocate, una quantità tale da poter effettuare un buon training in tempi tutto sommato contenuti.
È importante notare come la scelta di mantenere inalterato l'algoritmo nasce da due ragioni: la prima mantenere inalterati gli ottimi risultati relativi all'usabilità del dataset, la seconda (nonchè forse la più importante) è quella di voler andare ad operare direttamente sui dati anzichè sulla loro generazione.

\subsection{Regole seguite}
Per generare il dataset si è quindi scelto di utilizzare le stesse regole indicate dal dataset (\url{https://www.kaggle.com/datasets/dennisho/blackjack-hands/data}).
Le regole in questione sono:
\begin{itemize}
    \item \textbf{Shoe da 8 mazzi} (penetrazione di 6,5 mazzi)
    \item La prima carta dello shoe viene scartata
    \item Il Blackjack paga 3:2
    \item È possibile raddoppiare su qualsiasi combinazione iniziale di due carte
    \item Il raddoppio dopo lo split è consentito
    \item È possibile splittare qualsiasi coppia iniziale fino a un massimo di 4 mani
    \item Non è consentito il re-split degli Assi
    \item Dopo lo split degli Assi viene distribuita una sola carta per mano e non è possibile ottenere Blackjack
    \item Non è consentita la resa dopo uno split
    \item Il banco pesca su soft 17 (H17)
\end{itemize}
Bisogna notare anche quanto segue:
\begin{itemize}
    \item Tutte le mani sono giocate \textbf{heads-up} (un solo giocatore contro il banco)
    \item La puntata iniziale per ogni mano è sempre pari a 1
    \item Le carte 10, J, Q e K sono considerate equivalenti e registrate come 10
    \item Gli Assi sono sempre registrati come 11, indipendentemente dal loro valore effettivo nella mano
    \item I semi non vengono considerati e non sono registrati
    \item Il \textbf{Running Count} e il \textbf{True Count} (troncati all’intero) sono calcolati con il sistema \textbf{Hi-Lo} e registrati all’inizio di ogni mano, prima della distribuzione delle carte
    \item Il numero di carte rimanenti nello shoe è registrato all’inizio di ogni mano e include anche le carte che non verranno utilizzate a causa di una penetrazione inferiore al cento percento
\end{itemize}


\section{Prima pipeline}
\subsection{Esplorazione}
Il dataset generato necessità di varie operazioni di pulizia dei dati ed in generale di data engineering per renderlo consono ai nostri scopi.
C'è necessità di \textbf{Feature scaling}, \textbf{Feature construction}, \textbf{Feature extraction}. 
Iniziamo però da una fase iniziale di esplorazione dei dati, la quale serve per comprendere su quali aree andare ad agire.
Data la natura condivisa di questa fase abbiamo deciso di usare \textit{Colab}(quindi i comandi che andremo a specificare successivamente faranno riferimento alla sua sintassi).
Come prima cosa quindi abbiamo importato il file del dataset (in formato .csv) e abbiamo visualizzato le sue colonne. In particolare il dataset iniziale era composto da queste colonne: 
\begin{itemize}
    \item \textbf{shoe\_id}: Identificativo del mazzo utilizzato per la mano.
    \item \textbf{cards\_remaining}: Numero di carte rimanenti nel mazzo all'inizio della mano.
    \item \textbf{dealer\_up}: Carta scoperta del dealer.
    \item \textbf{initial\_hand}: Mano iniziale del giocatore.
    \item \textbf{dealer\_final}: Mano finale del dealer.
    \item \textbf{dealer\_final\_value}: Valore finale della mano del banco.
    \item \textbf{player\_final}: Mano finale del giocatore dopo tutte le azioni.
    \item \textbf{player\_final\_value}: Valore finale della mano del giocatore.
    \item \textbf{actions\_taken}: Sequenza di azioni effettuate dal giocatore.
    \item \textbf{run\_count}: Numero di round giocati nella simulazione.
    \item \textbf{true\_count}: Conteggio all'inizio della mano.
    \item \textbf{win}: Risultato della mano per il giocatore.
    \end{itemize}
Successivamente abbiamo individuato \textit{WIN} come colonna utile per la nostra classificazione, di fatto abbiamo analizzato quali fossero i valori che potesse assumere e li abbiamo raggruppati in tre categorie, ovvero minori di zero, uguali a zero e maggiori di zero.
Fatto ciò abbiamo visualizzato il numero di istanze per ciascuna categoria:
- 421940 istanze con win maggiore di zero.
- 493992 istanze con win minore di zero.
- 84068 istanze con win uguale a zero.
A primo impatto il dataset presentava uno sbilanciamento verso le "sconfitte", tuttavia abbiamo scelto di non considerarlo alla luce di due considerazioni: la prima è che è inerente nella natura del gioco (favorevole al banco) che siano presenti molte più sconfitte che vittorie, e la seconda è che andando a considerare semplicemente i casi "favorevoli" ovvero quelli dove la win è maggiore o uguale a zero, il dataset sarebbe apparso come bilanciato.
Successivamente abbiamo verificato quanti valori nulli fossero presenti nelle colonne, i risultati hanno mostrato che nessuna colonna presentava valori nulli. Ciò non era assolutamente inaspettato data la natura "sintetica" dei dati.
\subsection{Data Cleaning}
Siccome tutte le colonne del dataset non presentano dati mancanti, questa fase non comprende all'atto pratico nessun cambiamento.
\subsection{Feature Scaling}
Avendo precedentemente specificato che non vogliamo concentrarci sull'aspetto economico delle singole puntate, ci viene naturale
il voler normalizzare i valori di win per identificare semplicemente i tre casi possibili:
\begin{itemize}
    \item Vittoria (attualmente 0 < x <= 7, vorremmo solamente 1)
    \item Pareggio (attualmente == 0)
    \item Sconfitta (attualmente da < 0 a -7, vorremmo solamente -1)
\end{itemize}
Per fare ciò abbiamo valutato diverse opzioni:
\begin{description}
    \item[Normalizzazione min-max:] il problema di questo tipo di normalizzazione era che a noi interessava mantenere anche lo zero a fini statistici ma applicandola ciò non sarebbe possibile (se invece avessimo considerato lo 0 come parte della vittoria allora sarebbe stata perfetta)
    \item [Normalizzazione Z-score:] qui non avremmo avuto pieno controllo ma la trasformazione sarebbe stata attuata sulla densità media.
    \end{description}
Abbiamo quindi optato per una strategia di "Discretizzazione con soglie"(\textbf{da aggiungere nel glossario}) che ci permette di fare esattamente ciò che
ci serve.
\subsection{Feature Engineering}
Nonostante il lavoro effettuato nella fase precedente, il dataset risultava fortemente inadeguato ai nostri scopi, quindi in questa fase tramite tecniche di Feature Selection e Feature Construction abbiamo cercato di plasmarlo al meglio per i nostri scopi.
\subsubsection{Feature Selection}
Iniziamo da ciò che siamo andati a rimuovere.
Primo step è stato quello di eliminare shoe\_id in quanto è un semplice indicatore del mazzo di carte e non ha alcuna correlazione con la decisione nel nostro contesto.
Fatto ciò passiamo all'eliminazione di colonne che potrebbero causare \textbf{Data Leakage}, in particolare facciamo riferimento
a:
\begin{itemize}
    \item \textbf{dealer\_final}: rappresenta la mano finale del dealer e, di conseguenza, non è un'informazione disponibile al momento della decisione del giocatore.
    \item \textbf{dealer\_final\_value}: valore finale della mano del dealer; per le stesse motivazioni espresse sopra, questa informazione è osservabile solo a fine mano.    
    \item \textbf{player\_final}: descrive la mano finale del giocatore, includendo carte ottenute attraverso azioni future non ancora osservabili nel momento della decisione.
    \item \textbf{player\_final\_value}: valore finale della mano del giocatore; analogamente alla variabile precedente, non è disponibile prima del completamento della sequenza di azioni.
    \item \textbf{actions\_taken}: rappresenta un vero e proprio caso di \emph{data leakage}, in quanto codifica direttamente la sequenza di azioni che il modello dovrebbe invece apprendere a prevedere.
\end{itemize}
Detto ciò abbiamo eliminato anche run\_count, true\_count e cards\_remaining perchè relativi al conteggio delle carte.
\subsubsection{Feature Construction}
Una volta conclusa la fase di \emph{Feature Selection}, è stato necessario modificare alcune colonne del dataset al fine di renderle utilizzabili dal modello.
La prima trasformazione riguarda la variabile \textbf{initial\_hand}, che è rappresentata come una lista di carte. Questa rappresentazione risulta poco adatta all’utilizzo diretto da parte del modello; per questo motivo si è deciso di scomporla in tre differenti variabili:
\begin{itemize}
    \item \textbf{player\_sum}: la somma dei valori di tutte le carte presenti nella mano del giocatore
    \item \textbf{player\_is\_soft}: variabile binaria che indica se la mano è \emph{soft}, ovvero se contiene un asso valutabile come 11
    \item \textbf{player\_pair}: variabile binaria che indica se la mano è composta da due carte dello stesso valore e quindi se è possibile effettuare lo \emph{split}.
\end{itemize}
\subsection{Colonne finali del Dataset}
Al termine della fase di elaborazione, il dataset finale risulta composto dalle seguenti variabili:
\begin{itemize}
    \item \textbf{player\_sum}
    \item \textbf{player\_is\_soft}
    \item \textbf{player\_pair}
    \item \textbf{dealer\_up}
\end{itemize}
La variabile target è \textbf{win}, che indica l’esito della decisione presa dal giocatore, assumendo i valori di vittoria e sconfitta.
\subsection{Modeling}
Prima di parlare degli algoritmi utilizzati occorre fare delle premesse. Per scegliere i migliori parametri adatti agli algoritmi e il problema che stiamo affrontando abbiamo deciso di utilizzare \textbf{GridSearchCV} per identificare gli iperparametri. È una classe contenuta nella libreria scikit-learn che ci permette di testare più combinazioni di parametri automaticamente evitando di eseguire a mano i training.
La prima operazione effettuata è lo splitting del dataset per distinguere i dati di test e i dati per il training. Nello specifico l'80\% dei dati sarà utilizzato per il training e il 20\% per il testing. Avviene successivamente un ulteriore split dei dati di training per training e validazione, nello specifico il 78.5\%  per il training e il restante per la validazione. È stato inoltre fissato un seme randomico per rendere i test ripetibili. % Da aggiustare%
Infine stratify permette di suddividere il dataset in modo che ogni sottoinsieme mantenga la stessa identica proporzione di classi del dataset originale.
Per la prima versione di questa pipeline (Pipeline 1A) l'algoritmo utilizzato è un albero decisionale di classificazione (DecisionTreeClassifier) specificando i seguenti parametri: 

\begin{itemize}
    \item \textbf{ max\_depth che specifica la profondità massimache l'albero può raggiungere con i seguenti valori: [10,20,30]}
    \item \textbf{ min\_samples\_split: che determina numero minimo di campioni prima di effettuare un'ulteriore ramificazione. I valori sono: [2,5]}
    \item \textbf{ min\_samples\_ leaf, che determina il numero minimo di campioni che devono essere presenti nelle foglie. I valori sono: [1,2]}
\end{itemize}
\subsection{Evaluation}
%Needs improvments 
I risultati dell'algoritmo sono stati i seguenti: 
Best params: 'max\_depth': 10, 'min\_samples\_leaf': 1, 'min\_samples\_split': 2
  F1-Score Test: 0.6562
  Accuracy:  0.6844
  Precision:  0.7268
  Recall:  0.5982
  \begin{center}
      \includegraphics[scale=0.8, center]{Img/MatriceDiConfusionePipeline1.png}
  \end{center}
\subsection{Glossario}

\renewcommand{\arraystretch}{1.5} % Aumenta lo spazio verticale tra le righe
\setlength{\arrayrulewidth}{0.5pt}

\noindent
\begin{tabularx}{\textwidth}{>{\bfseries}l X} % Prima colonna in grassetto, seconda estesa
    \rowcolor{Gray!20} % Colore dell'intestazione
    Termine & Definizione \\ \toprule
    
    Data binning & Tecnica di data preprocessing utilizzata per diminuire l'errore osservabile.I dati originali sono ridotti a un piccolo range di intervalli decisi tramite varie metodologie. \\ 
    \midrule
    
    Data leakage & Problema di un modello di ML: il modello è capace di lavorare accuratamente solo in fase di addestramento e non in fase di rilascio. \\ 
    \midrule
 
    \bottomrule
\end{tabularx}

\end{document}
